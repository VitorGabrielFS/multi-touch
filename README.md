<div>
<h1> 
  <img width="40" height="40" src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" />
    Brasil-Visual-Touch
  <img src="https://github.com/user-attachments/assets/3b94c6d6-4440-4a15-9f08-7ca2091769c6" alt="logo visual touch" width="50" height="50">
</h1>
</div>

<div align="center"> 
<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&pause=1000&background=39000000&center=true&vCenter=true&width=600&lines=Visual-Touch;Samsung+Innovation+Campus+SIC;A+nova+fronteira+da+inclusão+digital" alt="Typing SVG" />
</a>
<img width='400' height='100' src="https://github.com/user-attachments/assets/480dcbb4-cef2-41ea-8dc4-27303433bb46" />
</div>

---

# 🦾 Visual Touch – Inclusão em Movimento

O **Visual Touch** nasceu como um projeto para controlar o cursor do mouse com os olhos, mas evoluiu para algo muito maior:  
um **hub de acessibilidade digital** que une **visão, voz e Libras** para criar uma interação fluida entre pessoas e máquinas.  

🚀 Hoje, o Visual Touch vai além:  
- Gesto com os **olhos** para controlar o mouse.  
- **Reconhecimento de voz** para comandos rápidos.  
- Tradução básica de **Libras para texto/voz**, aproximando mundos.  
- Possibilidade de **atalhos com gestos das mãos**, trazendo praticidade no dia a dia.  

Tudo isso com foco em **inclusão, autonomia e inovação**.  

---

## 🎥 Demonstrações

![miniatura](https://github.com/user-attachments/assets/2773a9cb-524c-4a2e-9e55-3ba819aa6644)  
![Captura de tela](https://github.com/user-attachments/assets/9824460e-8d72-415c-bc39-2dacdb91b3f6)  
![Captura de tela](https://github.com/user-attachments/assets/08f43fd7-c281-403a-8e91-60dee0c4b810)  
![Captura de tela](https://github.com/user-attachments/assets/c8e8a418-382a-4699-9c1b-db143f427f8c)  
![Captura de tela](https://github.com/user-attachments/assets/27011b53-bf8f-413e-923f-9fbc3e8ee715)  

🎬 [Assista a demonstração completa](https://www.youtube.com/watch?v=VWJLNymJehQ&t=20s)

---

## 🌍 Impacto e Benefícios

### Para Pessoas com Deficiências
- Controle total do computador sem usar as mãos.  
- Tradução de Libras para comunicação em tempo real.  
- Voz como alternativa para expressar comandos.  

### Para Profissionais Ocupados
- Mãos livres para multitarefas.  
- Atalhos personalizados com gestos e voz.  

### Para Todos
- Experiência tecnológica intuitiva, divertida e imersiva.  
- Uma nova forma de navegar e interagir com o computador.  

---

## 🧩 Funcionalidades Atuais

- 👁 **Controle do Cursor com os Olhos**  
- 👁‍🗨 **Cliques por piscar ou olhar fixado**  
- 🎙 **Comandos de Voz**  
- 🖐 **Gestos das mãos para atalhos**  
- 🤟 **Tradução de Libras (experimental)**  
- 🖥 **Compatível com câmeras comuns e sistemas Windows/Linux**  
- ⚙️ **Configuração de sensibilidade e calibração personalizada**  

---

## 🛠️ Tecnologias Utilizadas

- [MediaPipe](https://google.github.io/mediapipe/) – rastreamento de rosto, mãos e movimentos.  
- [OpenCV](https://opencv.org/) – visão computacional.  
- [PyAutoGUI](https://pyautogui.readthedocs.io/) – automação do cursor.  
- [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) – reconhecimento de voz.  
- [TensorFlow/Keras](https://www.tensorflow.org/) – modelos de IA para Libras.  

---

## 📋 Como Usar

1. Clone este repositório.  
2. Crie um ambiente virtual e instale as dependências com:  
   ```bash
   pip install -r requirements.txt
