<div>
<h1> 
  <img width="40" height="40" src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" />
    Brasil-Visual-Touch
  <img src="https://github.com/user-attachments/assets/3b94c6d6-4440-4a15-9f08-7ca2091769c6" alt="logo visual touch" width="50" height="50">
</h1>
</div>

<div align="center"> 
<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&pause=1000&background=39000000&center=true&vCenter=true&width=600&lines=Visual-Touch;Samsung+Innovation+Campus+SIC;A+nova+fronteira+da+inclusÃ£o+digital" alt="Typing SVG" />
</a>
<img width='400' height='100' src="https://github.com/user-attachments/assets/480dcbb4-cef2-41ea-8dc4-27303433bb46" />
</div>

---

# ğŸ¦¾ Visual Touch â€“ InclusÃ£o em Movimento

O **Visual Touch** nasceu como um projeto para controlar o cursor do mouse com os olhos, mas evoluiu para algo muito maior:  
um **hub de acessibilidade digital** que une **visÃ£o, voz e Libras** para criar uma interaÃ§Ã£o fluida entre pessoas e mÃ¡quinas.  

ğŸš€ Hoje, o Visual Touch vai alÃ©m:  
- Gesto com os **olhos** para controlar o mouse.  
- **Reconhecimento de voz** para comandos rÃ¡pidos.  
- TraduÃ§Ã£o bÃ¡sica de **Libras para texto/voz**, aproximando mundos.  
- Possibilidade de **atalhos com gestos das mÃ£os**, trazendo praticidade no dia a dia.  

Tudo isso com foco em **inclusÃ£o, autonomia e inovaÃ§Ã£o**.  

---

## ğŸ¥ DemonstraÃ§Ãµes

![miniatura](https://github.com/user-attachments/assets/2773a9cb-524c-4a2e-9e55-3ba819aa6644)  
![Captura de tela](https://github.com/user-attachments/assets/9824460e-8d72-415c-bc39-2dacdb91b3f6)  
![Captura de tela](https://github.com/user-attachments/assets/08f43fd7-c281-403a-8e91-60dee0c4b810)  
![Captura de tela](https://github.com/user-attachments/assets/c8e8a418-382a-4699-9c1b-db143f427f8c)  
![Captura de tela](https://github.com/user-attachments/assets/27011b53-bf8f-413e-923f-9fbc3e8ee715)  

ğŸ¬ [Assista a demonstraÃ§Ã£o completa](https://www.youtube.com/watch?v=VWJLNymJehQ&t=20s)

---

## ğŸŒ Impacto e BenefÃ­cios

### Para Pessoas com DeficiÃªncias
- Controle total do computador sem usar as mÃ£os.  
- TraduÃ§Ã£o de Libras para comunicaÃ§Ã£o em tempo real.  
- Voz como alternativa para expressar comandos.  

### Para Profissionais Ocupados
- MÃ£os livres para multitarefas.  
- Atalhos personalizados com gestos e voz.  

### Para Todos
- ExperiÃªncia tecnolÃ³gica intuitiva, divertida e imersiva.  
- Uma nova forma de navegar e interagir com o computador.  

---

## ğŸ§© Funcionalidades Atuais

- ğŸ‘ **Controle do Cursor com os Olhos**  
- ğŸ‘â€ğŸ—¨ **Cliques por piscar ou olhar fixado**  
- ğŸ™ **Comandos de Voz**  
- ğŸ– **Gestos das mÃ£os para atalhos**  
- ğŸ¤Ÿ **TraduÃ§Ã£o de Libras (experimental)**  
- ğŸ–¥ **CompatÃ­vel com cÃ¢meras comuns e sistemas Windows/Linux**  
- âš™ï¸ **ConfiguraÃ§Ã£o de sensibilidade e calibraÃ§Ã£o personalizada**  

---

## ğŸ› ï¸ Tecnologias Utilizadas

- [MediaPipe](https://google.github.io/mediapipe/) â€“ rastreamento de rosto, mÃ£os e movimentos.  
- [OpenCV](https://opencv.org/) â€“ visÃ£o computacional.  
- [PyAutoGUI](https://pyautogui.readthedocs.io/) â€“ automaÃ§Ã£o do cursor.  
- [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) â€“ reconhecimento de voz.  
- [TensorFlow/Keras](https://www.tensorflow.org/) â€“ modelos de IA para Libras.  

---

## ğŸ“‹ Como Usar

1. Clone este repositÃ³rio.  
2. Crie um ambiente virtual e instale as dependÃªncias com:  
   ```bash
   pip install -r requirements.txt
